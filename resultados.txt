	ANEXO 1: Resultados finales RAG tras la incorporación del filtrado de metadatos

Question: ¿Cuál es el artículo 1?
Response: El artículo 1 establece normas armonizadas para la introducción en el mercado, la puesta en servicio y la utilización de sistemas de inteligencia artificial («sistemas de IA») en la Unión, prohibiciones de determinadas prácticas de inteligencia artificial, requisitos específicos para los sistemas de IA de alto riesgo y obligaciones para los operadores de dichos sistemas, normas armonizadas de transparencia aplicables a ciertos tipos de sistemas de IA, y normas sobre el control y la vigilancia del mercado.
Full Results:
Source Nodes:
Node ID: 5d1bfce8-d9c0-432c-9a65-158323c4637a
Text: Artículo 1 Objeto El presente Reglamento establece: a)normas armonizadas para la introducción en el mercado, la puesta en servicio y la utilización de sistemas de inteligencia artificial («sistemas de IA») en la Unión; b)prohibiciones de determinadas prácticas de inteligencia artificial; c)requisitos específicos para los sistemas de IA de alto riesgo y obligaciones para los operadores de dichos sistemas; d)normas armonizadas de transparencia aplicables a los sistemas de IA destinados a interactuar con personas físicas, los sistemas de reconocimiento de emociones y los sistemas de categorización biométrica, así como a los sistemas de IA usados para generar o manipular imágenes, archivos de audio o vídeos; e)normas sobre el control y la vigilancia del mercado.
Metadata: {'articulo': 'Articulo 1'}
Score: 0.49563107472801027

================================================================================

Question: ¿Cuál es el artículo 2?
Response: El artículo 2 establece el ámbito de aplicación del Reglamento sobre sistemas de IA, especificando a quiénes se aplica y en qué situaciones no se aplica dicho reglamento.
Full Results:
Source Nodes:
Node ID: ffdf704f-327c-4a02-b077-e96350e18c2c
Text: Artículo 2 Ámbito de aplicación 1.El presente Reglamento es aplicable a: a)los proveedores que introduzcan en el mercado o pongan en servicio sistemas de IA en la Unión, con independencia de si dichos proveedores están establecidos en la Unión o en un tercer país; b)los usuarios de sistemas de IA que se encuentren en la Unión; c)los proveedores y usuarios de sistemas de IA que se encuentren en un tercer país, cuando la información de salida generada por el sistema se utilice en la Unión. 2.A los sistemas de IA de alto riesgo que sean componentes de seguridad de productos o sistemas, o que sean en sí mismos productos o sistemas, comprendidos en el ámbito de aplicación de los actos que figuran a continuación, únicamente se les aplicará el artículo 84 del presente Reglamento: a)el Reglamento (CE) n.º 300/2008; b)el Reglamento (UE) n.º 167/2013; c)el Reglamento (UE) n.º 168/2013; d)la Directiva 2014/90/UE; e)la Directiva (UE) 2016/797; f)el Reglamento (UE) 2018/858; g)el Reglamento (UE) 2018/1139; h)el Reglamento (UE) 2019/2144. 3.El presente Reglamento no se aplicará a los sistemas de IA desarrollados o utilizados exclusivamente con fines militares. 4.El presente Reglamento no se aplicará a las autoridades públicas de terceros países ni a las organizaciones internacionales que entren dentro del ámbito de aplicación de este Reglamento conforme al apartado 1 cuando dichas autoridades u organizaciones utilicen sistemas de IA en el marco de acuerdos internacionales con fines de aplicación de la ley y cooperación judicial con la Unión o con uno o varios Estados miembros. 5.El presente Reglamento no afectará a la aplicación de las disposiciones relativas a la responsabilidad de los prestadores de servicios intermediarios que figuran en el capítulo II, sección IV, de la Directiva 2000/31/CE del Parlamento Europeo y del Consejo60[que deben sustituirse por las disposiciones correspondientes de la Ley de Servicios Digitales].
Metadata: {'articulo': 'Articulo 2'}
Score: 0.5298149093895472

================================================================================

Question: Cuál es el artículo 3?
Response: El artículo 3 define una serie de términos clave relacionados con el Reglamento sobre sistemas de inteligencia artificial.
Full Results:
Source Nodes:
Node ID: 5350d5a9-588f-4094-bb5f-6ff570866434
Text: Artículo 3 Definiciones A los efectos del presente Reglamento, se entenderá por: 1)«Sistema de inteligencia artificial (sistema de IA)»: elsoftwareque se desarrolla empleando una o varias de las técnicas y estrategias que figuran en el anexo I y que puede, para un conjunto determinado de objetivos definidos por seres humanos, generar información de salida como contenidos, predicciones, recomendaciones o decisiones que influyan en los entornos con los que interactúa. 2)«Proveedor»: toda persona física o jurídica, autoridad pública, agencia u organismo de otra índole que desarrolle un sistema de IA o para el que se haya desarrollado un sistema de IA con vistas a introducirlo en el mercado o ponerlo en servicio con su propio nombre o marca comercial, ya sea de manera remunerada o gratuita. 3)«Proveedor a pequeña escala»: todo proveedor que sea una microempresa o una pequeña empresa en el sentido de la Recomendación 2003/361/CE de la Comisión61. 4)«Usuario»: toda persona física o jurídica, autoridad pública, agencia u organismo de otra índole que utilice un sistema de IA bajo su propia autoridad, salvo cuando su uso se enmarque en una actividad personal de carácter no profesional. 5)«Representante autorizado»: toda persona física o jurídica establecida en la Unión que haya recibido el mandato por escrito de un proveedor de un sistema de IA para cumplir las obligaciones y llevar a cabo los procedimientos establecidos en el presente Reglamento en representación de dicho proveedor. 6)«Importador»: toda persona física o jurídica establecida en la Unión que introduzca en el mercado o ponga en servicio un sistema de IA que lleve el nombre o la marca comercial de una persona física o jurídica establecida fuera de la Unión. 7)«Distribuidor»: toda persona física o jurídica que forme parte de la cadena de suministro, distinta del proveedor o el importador, que comercializa un sistema de IA en el mercado de la Unión sin influir sobre sus propiedades. 8)«Operador»: el proveedor, el usuario, el representante autorizado, el importador y el distribuidor. 9)«Introducción en el mercado»: la primera comercialización en el mercado de la Unión de un sistema de IA. 10)«Comercialización»: todo suministro de un sistema de IA para su distribución o utilización en el mercado de la Unión en el transcurso de una actividad comercial, ya se produzca el suministro de manera remunerada o gratuita. 11)«Puesta en servicio»: el suministro de un sistema de IA para su primer uso directamente al usuario o para uso propio en el mercado de la Unión de acuerdo con su finalidad prevista. 12)«Finalidad prevista»: el uso para el que un proveedor concibe un sistema de IA, incluido el contexto y las condiciones de uso concretas, según la información facilitada por el proveedor en las instrucciones de uso, los materiales y las declaraciones de promoción y venta, y la documentación técnica. 13)«Uso indebido razonablemente previsible»: la utilización de un sistema de IA de un modo que no corresponde a su finalidad prevista, pero que puede derivarse de un comportamiento humano o una interacción con otros sistemas razonablemente previsible. 14)«Componente de seguridad de un producto o sistema»: un componente de un producto o un sistema que cumple una función de seguridad para dicho producto o sistema, o cuyo fallo o defecto de funcionamiento pone en peligro la salud y la seguridad de las personas o los bienes. 15)«Instrucciones de uso»: la información facilitada por el proveedor para informar al usuario, en particular, de la finalidad prevista y de la correcta utilización de un sistema de IA, lo que incluye el entorno geográfico, conductual o funcional específico en el que se pretende utilizar el sistema de IA de alto riesgo. 16)«Recuperación de un sistema de IA»: toda medida encaminada a conseguir que el proveedor recupere un sistema de IA puesto a disposición de los usuarios. 17)«Retirada de un sistema de IA»: toda medida destinada a impedir la distribución, la exposición y la oferta de un sistema de IA. 18)«Funcionamiento de un sistema de IA»: la capacidad de un sistema de IA para alcanzar su finalidad prevista. 19)«Autoridad notificante»: la autoridad nacional responsable de establecer y llevar a cabo los procedimientos necesarios para la evaluación, designación y notificación de los organismos de evaluación de la conformidad, así como de su seguimiento. 20)«Evaluación de la conformidad»: el proceso por el que se verifica si se cumplen los requisitos establecidos en el título III, capítulo 2, del presente Reglamento en relación con un sistema de IA. 21)«Organismo de evaluación de la conformidad»: un organismo independiente que desempeña actividades de evaluación de la conformidad, entre las que figuran la prueba, la certificación y la inspección. 22)«Organismo notificado»: un organismo de evaluación de la conformidad designado con arreglo al presente Reglamento y otra legislación de armonización pertinente de la Unión. 23)«Modificación sustancial»: un cambio en un sistema de IA tras su introducción en el mercado o puesta en servicio que afecte al cumplimiento por su parte de los requisitos establecidos en el título III, capítulo 2, del presente Reglamento o que provoque la modificación de la finalidad prevista para la que se ha evaluado al sistema de IA en cuestión. 24)«Marcado CE de conformidad» o «marcado CE»: un marcado con el que un proveedor indica que un sistema de IA es conforme con los requisitos establecidos en el título III, capítulo 2, del presente Reglamento y otra legislación de la Unión aplicable que armonice las condiciones para la comercialización de productos (la «legislación de armonización de la Unión») y prevea su colocación. 25)«Seguimiento posterior a la comercialización»: todas las actividades realizadas por los proveedores de sistemas de IA destinadas a recopilar y examinar de forma proactiva la experiencia obtenida con el uso de sistemas de IA que introducen en el mercado o ponen en servicio, con objeto de detectar la posible necesidad de aplicar inmediatamente cualquier tipo de medida correctora o preventiva que resulte necesaria. 26)«Autoridad de vigilancia del mercado»: la autoridad nacional que lleva a cabo las actividades y adopta las medidas previstas en el Reglamento (UE) 2019/1020. 27)«Norma armonizada»: una norma europea conforme a la definición que figura en el artículo 2, punto 1, letra c), del Reglamento (UE) n.º 1025/2012. 28)«Especificaciones comunes»: un documento, distinto de una norma, con soluciones técnicas que proponen una forma de cumplir determinados requisitos y obligaciones establecidos en el presente Reglamento. 29)«Datos de entrenamiento»: los datos usados para entrenar un sistema de IA mediante el ajuste de sus parámetros entrenables, entre los que se incluyen los pesos de una red neuronal. 30)«Datos de validación»: los datos usados para proporcionar una evaluación del sistema de IA entrenado y adaptar sus parámetros no entrenables y su proceso de aprendizaje, entre otras cosas, para evitar el sobreajuste. El conjunto de datos de validación puede ser un conjunto de datos independiente o formar parte del conjunto de datos de entrenamiento, ya sea como una división fija o variable. 31)«Datos de prueba»: los datos usados para proporcionar una evaluación independiente del sistema de IA entrenado y validado, con el fin de confirmar el funcionamiento previsto de dicho sistema antes de su introducción en el mercado o su puesta en servicio. 32)«Datos de entrada»: los datos proporcionados a un sistema de IA u obtenidos directamente por él a partir de los cuales produce la información de salida. 33)«Datos biométricos»: los datos personales obtenidos a partir de un tratamiento técnico específico, relativos a las características físicas, fisiológicas o conductuales de una persona física que permitan o confirmen la identificación única de dicha persona, como imágenes faciales o datos dactiloscópicos. 34)«Sistema de reconocimiento de emociones»: un sistema de IA destinado a detectar o deducir las emociones o las intenciones de personas físicas a partir de sus datos biométricos. 35)«Sistema de categorización biométrica»: un sistema de IA destinado a asignar a personas físicas a categorías concretas, como un sexo, edad, color de pelo, color de ojos, tatuajes, origen étnico u orientación sexual o política, en función de sus datos biométricos. 36)«Sistema de identificación biométrica remota»: un sistema de IA destinado a identificar a personas físicas a distancia comparando sus datos biométricos con los que figuran en una base de datos de referencia, y sin que el usuario del sistema de IA sepa de antemano si la persona en cuestión se encontrará en dicha base de datos y podrá ser identificada. 37)«Sistema de identificación biométrica remota “en tiempo real”»: un sistema de identificación biométrica remota en el que la recogida de los datos biométricos, la comparación y la identificación se producen sin una demora significativa. Este término engloba no solo la identificación instantánea, sino también demoras mínimas limitadas, a fin de evitar su elusión. 38)«Sistema de identificación biométrica remota “en diferido”»: todo sistema de identificación biométrica remota que no sea un sistema de identificación biométrica remota «en tiempo real». 39)«Espacio de acceso público»: cualquier lugar físico accesible para el público, con independencia de que deban cumplirse determinadas condiciones para acceder a él. 40)«Autoridad encargada de la aplicación de la ley»: a)toda autoridad pública competente para la prevención, la investigación, la detección o el enjuiciamiento de infracciones penales o la ejecución de sanciones penales, incluidas la protección y prevención frente a amenazas para la seguridad pública; o b)cualquier otro órgano o entidad a quien el Derecho del Estado miembro haya confiado el ejercicio de la autoridad pública y las competencias públicas a efectos de prevención, investigación, detección o enjuiciamiento de infracciones penales o ejecución de sanciones penales, incluidas la protección y prevención frente a amenazas para la seguridad pública. 41)«Aplicación de la ley»: las actividades realizadas por las autoridades encargadas de la aplicación de la ley para la prevención, la investigación, la detección o el enjuiciamiento de infracciones penales o la ejecución de sanciones penales, incluidas la protección y prevención frente a amenazas para la seguridad pública. 42)«Autoridad nacional de supervisión»: la autoridad a la que un Estado miembro asigna la responsabilidad de ejecutar y aplicar el presente Reglamento, coordinar las actividades encomendadas a dicho Estado miembro, actuar como el punto de contacto único para la Comisión, y representar al Estado miembro en cuestión ante el Comité Europeo de Inteligencia Artificial. 43)«Autoridad nacional competente»: la autoridad nacional de supervisión, la autoridad notificante y la autoridad de vigilancia del mercado. 44)«Incidente grave»: todo incidente que, directa o indirectamente, tenga, pueda haber tenido o pueda tener alguna de las siguientes consecuencias: a)el fallecimiento de una persona o daños graves para su salud, para los bienes o para el medio ambiente; b)una alteración grave e irreversible de la gestión y el funcionamiento de infraestructura crítica.
Metadata: {'articulo': 'Articulo 3'}
Score: 0.5397333670681347

================================================================================

Question: ¿Cuál es el artículo 4?
Response: El artículo 4 otorga a la Comisión los poderes para adoptar actos delegados con el fin de modificar la lista de técnicas y estrategias en el anexo I, para adaptarla a la evolución del mercado y los avances tecnológicos, basándose en características similares a las técnicas y estrategias ya incluidas en ella.
Full Results:
Source Nodes:
Node ID: 2b500101-1816-45a4-ac92-459741536048
Text: Artículo 4 Modificaciones del anexo I Se otorgan a la Comisión los poderes para adoptar actos delegados de conformidad con el artículo 73 al objeto de modificar la lista de técnicas y estrategias que figura en el anexo I, con miras a adaptar dicha lista a la evolución del mercado y los avances tecnológicos sobre la base de características que sean similares a las técnicas y las estrategias incluidas en ella. TÍTULO II PRÁCTICAS DE INTELIGENCIA ARTIFICIAL PROHIBIDAS
Metadata: {'articulo': 'Articulo 4'}
Score: 0.4937516161146333

================================================================================

Question: Resume el artículo 6
Response: El artículo 6 establece las reglas de clasificación para los sistemas de IA de alto riesgo. Un sistema de IA se considera de alto riesgo si cumple dos condiciones: está destinado a ser utilizado como componente de seguridad de un producto específico o es en sí mismo uno de esos productos, y debe someterse a una evaluación de conformidad por un organismo independiente según la legislación de armonización de la Unión. Además, se consideran de alto riesgo los sistemas de IA mencionados en el anexo III.
Full Results:
Source Nodes:
Node ID: 49ffa745-1092-4adb-b819-c530b6f9aa28
Text: Artículo 6 Reglas de clasificación para los sistemas de IA de alto riesgo 1.Un sistema de IA se considerará de alto riesgo cuando reúna las dos condiciones que se indican a continuación, con independencia de si se ha introducido en el mercado o se ha puesto en servicio sin estar integrado en los productos que se mencionan en las letras a) y b): a)el sistema de IA está destinado a ser utilizado como componente de seguridad de uno de los productos contemplados en la legislación de armonización de la Unión que se indica en el anexo II, o es en sí mismo uno de dichos productos; b)conforme a la legislación de armonización de la Unión que se indica en el anexo II, el producto del que el sistema de IA es componente de seguridad, o el propio sistema de IA como producto, debe someterse a una evaluación de la conformidad realizada por un organismo independiente para su introducción en el mercado o puesta en servicio. 2.Además de los sistemas de IA de alto riesgo mencionados en el apartado 1, también se considerarán de alto riesgo los sistemas de IA que figuran en el anexo III.
Metadata: {'articulo': 'Articulo 6'}
Score: 0.436827677145826

================================================================================

Question: ¿Cuál es el artículo 18?
Response: El artículo 18 establece la obligación para los proveedores de sistemas de IA de alto riesgo de elaborar la documentación técnica mencionada en el artículo 11 con arreglo al anexo IV. Además, en el caso de los proveedores que sean entidades de crédito reguladas por la Directiva 2013/36/UE, la documentación técnica formará parte de la documentación relativa a los sistemas, procedimientos y mecanismos de gobernanza interna que figuran en el artículo 74 de dicha Directiva.
Full Results:
Source Nodes:
Node ID: 37602b1c-426d-40d2-8d3e-2f2a1f40bc2d
Text: Artículo 18 Obligación de elaborar documentación técnica 1.Los proveedores de sistemas de IA de alto riesgo elaborarán la documentación técnica mencionada en el artículo 11 con arreglo al anexo IV. 2.En el caso de los proveedores que sean entidades de crédito reguladas por la Directiva 2013/36/UE, la documentación técnica formará parte de la documentación relativa a los sistemas, procedimientos y mecanismos de gobernanza interna que figuran en el artículo 74 de dicha Directiva.
Metadata: {'articulo': 'Articulo 18'}
Score: 0.4579120699976608

================================================================================

Question: ¿Cuál es el artículo 55?
Response: El artículo 55 se refiere a las medidas dirigidas a proveedores y usuarios a pequeña escala en relación con la inteligencia artificial. Incluye disposiciones como proporcionar acceso prioritario a espacios de pruebas, organizar actividades de sensibilización específicas y establecer canales de comunicación para orientar y responder a dudas sobre la aplicación del Reglamento. También menciona la consideración de los intereses y necesidades de los proveedores a pequeña escala en la fijación de tasas para la evaluación de la conformidad.
Full Results:
Source Nodes:
Node ID: 7e56f773-b447-4505-a3f7-3475479151ad
Text: Artículo 55 Medidas dirigidas a proveedores y usuarios a pequeña escala 1.Los Estados miembros adoptarán las medidas siguientes: a)proporcionar a los proveedores a pequeña escala y a las empresas emergentes un acceso prioritario a los espacios controlados de pruebas para la IA, siempre y cuando cumplan los requisitos de admisibilidad; b)organizar actividades de sensibilización específicas acerca de la aplicación del presente Reglamento, adaptadas a las necesidades de los proveedores y usuarios a pequeña escala; c)establecer, cuando proceda, un canal específico para la comunicación con los proveedores y usuarios a pequeña escala, así como con otros agentes innovadores, con objeto de formular orientaciones y responder a las dudas planteadas acerca de la aplicación del presente Reglamento. 2.Se tendrán en cuenta los intereses y necesidades específicos de los proveedores a pequeña escala a la hora de fijar las tasas para la evaluación de la conformidad en virtud del artículo 43, y reducir dichas tasas en proporción a su tamaño y al del mercado. TÍTULO VI GOBERNANZA Capítulo 1 Comité Europeo de Inteligencia Artificial
Metadata: {'articulo': 'Articulo 55'}
Score: 0.4128691350947766

================================================================================

Question: ¿Qué artículo habla sobre las sanciones?
Response: El artículo que habla sobre las sanciones es el Artículo 71.
Full Results:
Source Nodes:
Node ID: 6844767b-1c4e-4f48-b2f6-3c79148f0b2f
Text: Artículo 71 Sanciones 1.De conformidad con los términos y condiciones establecidos en el presente Reglamento, los Estados miembros determinarán el régimen de sanciones, incluidas las multas administrativas, aplicable a las infracciones del presente Reglamento y adoptarán todas las medidas necesarias para garantizar su aplicación adecuada y efectiva. Las sanciones establecidas serán efectivas, proporcionadas y disuasorias. Tendrán particularmente en cuenta los intereses de los proveedores a pequeña escala y las empresas emergentes, así como su viabilidad económica. 2.Los Estados miembros comunicarán a la Comisión el régimen establecido y las medidas adoptadas y le notificarán, sin demora, cualquier modificación posterior de los mismos. 3.Las siguientes infracciones estarán sujetas a multas administrativas de hasta 30 000 000 EUR o, si el infractor es una empresa, de hasta el 6 % del volumen de negocio total anual mundial del ejercicio financiero anterior, si esta cuantía fuese superior: a)incumplimiento de la prohibición de las prácticas de inteligencia artificial a que se refiere el artículo 5; b)incumplimiento de los requisitos establecidos en el artículo 10 por parte del sistema de IA. 4.El incumplimiento por parte del sistema de IA de cualquiera de los requisitos u obligaciones establecidos en el presente Reglamento distintos de los dispuestos en los artículos 5 y 10 estará sujeto a multas administrativas de hasta 20 000 000 EUR o, si el infractor es una empresa, de hasta el 4 % del volumen de negocio total anual mundial del ejercicio financiero anterior, si esta cuantía fuese superior. 5.La presentación de información inexacta, incompleta o engañosa a organismos notificados y a las autoridades nacionales competentes en respuesta a una solicitud estará sujeta a multas administrativas de hasta 10 000 000 EUR o, si el infractor es una empresa, de hasta el 2 % del volumen de negocio total anual mundial del ejercicio financiero anterior, si esta cuantía fuese superior. 6.Al decidir la cuantía de la multa administrativa en cada caso concreto se tomarán en consideración todas las circunstancias pertinentes de la situación correspondiente y se tendrá debidamente en cuenta lo siguiente: a)la naturaleza, la gravedad y la duración de la infracción y de sus consecuencias; b)si otras autoridades de vigilancia del mercado han impuesto ya multas administrativas al mismo operador por la misma infracción; c)el tamaño y la cuota de mercado del operador que comete la infracción. 7.Cada Estado miembro establecerá normas que determinen si es posible, y en qué medida, imponer multas administrativas a autoridades y organismos públicos establecidos en dicho Estado miembro. 8.En función del ordenamiento jurídico de los Estados miembros, las normas relativas a las multas administrativas podrán aplicarse de tal modo que las multas las impongan órganos jurisdiccionales nacionales competentes u otros organismos, según proceda en dichos Estados miembros. La aplicación de dichas normas en estos Estados miembros tendrá un efecto equivalente.
Metadata: {'articulo': 'Articulo 71'}
Score: 0.5421670109755813

================================================================================

Question: ¿Cuáles son los objetivos específicos que la Comisión Europea busca alcanzar con la propuesta de Reglamento sobre inteligencia artificial?
Response: La Comisión Europea busca alcanzar los siguientes objetivos específicos con la propuesta de Reglamento sobre inteligencia artificial: garantizar la seguridad y el respeto a la legislación vigente en materia de derechos fundamentales y valores de la Unión en los sistemas de IA introducidos en el mercado de la UE, asegurar la seguridad jurídica para fomentar la inversión e innovación en IA, mejorar la gobernanza y la aplicación efectiva de la legislación en derechos fundamentales y requisitos de seguridad en los sistemas de IA, y facilitar el desarrollo de un mercado único para un uso legal, seguro y fiable de las aplicaciones de IA y evitar la fragmentación del mercado.
Full Results:
Source Nodes:
Node ID: 244c24e0-0134-4168-8398-58f0d6af1d0a
Text: los principios de proporcionalidad, subsidiariedad y mejora de la legislación. En este contexto político, la Comisión propone un marco reglamentario sobre inteligencia artificial con los siguientes objetivos específicos: garantizar que los sistemas de IA introducidos y usados en el mercado de la UE sean seguros y respeten la legislación vigente en materia de derechos fundamentales y valores de la Unión; ·garantizar la seguridad jurídica para facilitar la inversión e innovación en IA; ·mejorar la gobernanza y la aplicación efectiva de la legislación vigente en materia de derechos fundamentales y los requisitos de seguridad aplicables a los sistemas de IA; ·facilitar el desarrollo de un mercado único para hacer un uso legal, seguro y fiable de las aplicaciones de IA y evitar la fragmentación del mercado. Para alcanzar dichos objetivos, la presente propuesta presenta un enfoque normativo horizontal, equilibrado y proporcionado, para la IA, que se limita a establecer los requisitos
Metadata: {}
Score: 0.7526489346937205

================================================================================

Question: ¿Cómo se garantiza la coherencia de la propuesta con otras políticas y legislaciones de la Unión Europea?
Response: La coherencia de la propuesta con otras políticas y legislaciones de la Unión Europea se garantiza mediante su plena conformidad con la legislación vigente de la Unión aplicable a los sectores donde se utilizan o se prevé que se utilicen sistemas de IA de alto riesgo. Además, se asegura la coherencia con la Carta de los Derechos Fundamentales de la Unión Europea y el Derecho derivado de la Unión en áreas como protección de datos, protección de los consumidores, no discriminación e igualdad de género. La propuesta se entiende sin afectar al Reglamento General de Protección de Datos y la Directiva sobre protección de datos en el ámbito penal, complementándolos con normas armonizadas para el diseño, desarrollo y uso de ciertos sistemas de IA de alto riesgo, junto con restricciones específicas.
Full Results:
Source Nodes:
Node ID: 9c2790f1-7a35-4269-8ef1-294979922e50
Text: y las empresas emergentes. 1.2.Coherencia con las disposiciones existentes en la misma política sectorial Debido a su carácter horizontal, la propuesta debe ser plenamente coherente con la legislación de la Unión vigente aplicable a los sectores donde ya se utilizan o es probable que se utilicen en un futuro próximo sistemas de IA de alto riesgo. También está garantizada su coherencia con la Carta de los Derechos Fundamentales de la Unión Europea y el Derecho derivado de la Unión vigente en materia de protección de datos, protección de los consumidores, no discriminación e igualdad de género. La propuesta debe entenderse sin perjuicio del Reglamento General de Protección de Datos [Reglamento (UE) 2016/679] y la Directiva sobre protección de datos en el ámbito penal [Directiva (UE) 2016/680], a los que complementa con un conjunto de normas armonizadas aplicables al diseño, el desarrollo y la utilización de determinados sistemas de IA de alto riesgo y con restricciones de determinados
Metadata: {}
Score: 0.6305011738559213

================================================================================

Question: ¿Qué enfoque propone la Comisión Europea para gestionar los sistemas de inteligencia artificial de alto riesgo?
Response: La Comisión Europea propone establecer espacios comunes europeos de datos y facilitar el intercambio de datos entre empresas y con los Gobiernos para brindar un acceso fiable, responsable y no discriminatorio a datos de alta calidad con los que entrenar, validar y probar los sistemas de inteligencia artificial de alto riesgo.
Full Results:
Source Nodes:
Node ID: 59de0bc4-86e7-4dea-ae4b-a600103d0927
Text: el sesgo de los sistemas de IA de alto riesgo se vigile, detecte y corrija. (45)Para poder desarrollar sistemas de IA de alto riesgo, determinados agentes, tales como proveedores, organismos notificados y otras entidades pertinentes, como centros de innovación digital, centros de ensayo y experimentación e investigadores, deben tener acceso a conjuntos de datos de alta calidad en sus respectivos campos de actividad relacionados con el presente Reglamento y poder utilizarlos. Los espacios comunes europeos de datos establecidos por la Comisión y la facilitación del intercambio de datos entre empresas y con los Gobiernos en aras del interés público serán esenciales para brindar un acceso fiable, responsable y no discriminatorio a datos de alta calidad con los que entrenar, validar y probar los sistemas de IA. Por ejemplo, en el ámbito de la salud, el espacio europeo de datos sanitarios facilitará el acceso no discriminatorio a datos sanitarios y el entrenamiento, a partir de esos
Metadata: {}
Score: 0.7334598291995202

================================================================================

Question: ¿Qué impacto se anticipa que tendrá la propuesta sobre los derechos fundamentales y la seguridad de las personas?
Response: Se anticipa que la propuesta tendrá un impacto positivo en los derechos fundamentales, como el derecho a la tutela judicial efectiva, la presunción de inocencia, los derechos de la defensa, las condiciones de trabajo justas, la protección de los consumidores, los derechos del niño, la integración de las personas discapacitadas, el nivel de protección del medio ambiente y la seguridad de las personas.
Full Results:
Source Nodes:
Node ID: fd8b2fc8-cde9-4a1a-90e2-7991f7e71063
Text: reunión (artículo 12), y garantizar el derecho a la tutela judicial efectiva y a un juez imparcial, la presunción de inocencia y los derechos de la defensa (artículos 47 y 48), así como el principio general de buena administración. Asimismo, al ser aplicable en determinados ámbitos, la propuesta tendrá efectos positivos en los derechos de diversos grupos especiales, como los derechos de los trabajadores a unas condiciones de trabajo justas y equitativas (artículo 31), un elevado nivel de protección de los consumidores (artículo 28), los derechos del niño (artículo 24) y la integración de las personas discapacitadas (artículo 26). El derecho a un nivel elevado de protección del medio ambiente y la mejora de su calidad (artículo 37) también es pertinente, en particular en lo que respecta a la salud y la seguridad de las personas. Además, las obligaciones relativas a la realización de pruebasex ante, la gestión de riesgos y la vigilancia humana facilitarán el respeto de otros derechos
Metadata: {}
Score: 0.5781005356925516

================================================================================

Question: ¿Cuáles son las principales preocupaciones y recomendaciones expresadas por las partes interesadas durante la consulta sobre la inteligencia artificial?
Response: Las principales preocupaciones expresadas por las partes interesadas durante la consulta sobre la inteligencia artificial incluyen las implicaciones tecnológicas y sociales de la IA. Además, las partes interesadas formularon comentarios y presentaron documentos de posición adicionales. Las recomendaciones expresadas se basaron en un enfoque inclusivo, con más de 1,250 partes interesadas participando en los debates y presentando sus puntos de vista.
Full Results:
Source Nodes:
Node ID: 8a3dbca1-f8c8-44b9-ac44-21317e73402f
Text: mil partes interesadas celebran debates sobre las implicaciones tecnológicas y sociales de la IA, los cuales culminan con la celebración de una asamblea anual en la materia. ElLibro Blancosobre la IA profundizó más en este enfoque inclusivo, lo que animó a más de 1 250 partes interesadas a formular comentarios y a presentar más de 450 documentos de posición adicionales. En consecuencia, la Comisión publicó una evaluación inicial de impacto que, a su vez, dio lugar a más de 130 comentarios27. También se organizaronotros talleres y eventos con las partes interesadas, en cuyos resultados se fundamenta el análisis de la evaluación de impacto y las opciones que se plantean en la presente propuesta28. Asimismo, se encargó unestudio externodestinado a su utilización como material para la evaluación de impacto. 3.3.Evaluación de impacto En consonancia con su política de «legislar mejor», la Comisión sometió la presente propuesta a una evaluación de impacto que fue examinada por su Comité de
Metadata: {}
Score: 0.7180949885927624

================================================================================

Question: ¿Cuáles son las disposiciones del artículo 5 del reglamento respecto a la prohibición de ciertas prácticas de inteligencia artificial, y qué justificación se ofrece para estas prohibiciones?
Response: El artículo 5 del reglamento establece que están prohibidas ciertas prácticas de inteligencia artificial, como el uso de técnicas subliminales para alterar el comportamiento de una persona de manera perjudicial, aprovechar vulnerabilidades de grupos específicos para provocar perjuicios físicos o psicológicos, y la evaluación social basada en datos personales o de personalidad. Estas prohibiciones se justifican en la protección de la integridad física y psicológica de las personas, así como en evitar tratamientos injustificados o desproporcionados hacia grupos específicos.
Full Results:
Source Nodes:
Node ID: 0b36ff35-bac5-49d0-b594-89ac93a4c1cf
Text: Artículo 5  1.Estarán prohibidas las siguientes prácticas de inteligencia artificial: a)La introducción en el mercado, la puesta en servicio o la utilización de un sistema de IA que se sirva de técnicas subliminales que trasciendan la conciencia de una persona para alterar de manera sustancial su comportamiento de un modo que provoque o sea probable que provoque perjuicios físicos o psicológicos a esa persona o a otra. b)La introducción en el mercado, la puesta en servicio o la utilización de un sistema de IA que aproveche alguna de las vulnerabilidades de un grupo específico de personas debido a su edad o discapacidad física o mental para alterar de manera sustancial el comportamiento de una persona que pertenezca a dicho grupo de un modo que provoque o sea probable que provoque perjuicios físicos o psicológicos a esa persona o a otra. c)La introducción en el mercado, la puesta en servicio o la utilización de sistemas de IA por parte de las autoridades públicas o en su representación con el fin de evaluar o clasificar la fiabilidad de personas físicas durante un período determinado de tiempo atendiendo a su conducta social o a características personales o de su personalidad conocidas o predichas, de forma que la clasificación social resultante provoque una o varias de las situaciones siguientes: i)un trato perjudicial o desfavorable hacia determinadas personas físicas o colectivos enteros en contextos sociales que no guarden relación con los contextos donde se generaron o recabaron los datos originalmente; ii)un trato perjudicial o desfavorable hacia determinadas personas físicas o colectivos enteros que es injustificado o desproporcionado con respecto a su comportamiento social o la gravedad de este. d)El uso desistemas de identificación biométrica remota «en tiempo real» en espacios de acceso público con fines de aplicación de la ley, salvo y en la medida en que dicho uso sea estrictamente necesario para alcanzar uno o varios de los objetivos siguientes: i)la búsqueda selectiva de posibles víctimas concretas de un delito, incluidos menores desaparecidos; ii)la prevención de una amenaza específica, importante e inminente para la vida o la seguridad física de las personas físicas o de un atentado terrorista; iii)la detección, la localización, la identificación o el enjuiciamiento de la persona que ha cometido o se sospecha que ha cometido alguno de los delitos mencionados en el artículo 2, apartado 2, de la Decisión Marco 2002/584/JAI del Consejo62, para el que la normativa en vigor en el Estado miembro implicado imponga una pena o una medida de seguridad privativas de libertad cuya duración máxima sea al menos de tres años, según determine el Derecho de dicho Estado miembro. 2.El uso de sistemas de identificación biométrica remota «en tiempo real» en espacios de acceso público con fines de aplicación de la ley para conseguir cualquiera de los objetivos mencionados en el apartado 1, letra d), tendrá en cuenta los siguientes aspectos: a)la naturaleza de la situación que dé lugar al posible uso, y en particular la gravedad, probabilidad y magnitud del perjuicio que se produciría de no utilizarse el sistema; b)las consecuencias que utilizar el sistema tendría para los derechos y las libertades de las personas implicadas, y en particular la gravedad, probabilidad y magnitud de dichas consecuencias. Además, el uso de sistemas de identificación biométrica remota «en tiempo real» en espacios de acceso público con fines de aplicación de la ley para cualquiera de los objetivos mencionados en el apartado 1, letra d), cumplirá salvaguardias y condiciones necesarias y proporcionadas en relación con el uso, en particular en lo que respecta a las limitaciones temporales, geográficas y personales. 3.Con respecto al apartado 1, letra d), y el apartado 2, cualquier uso concreto de un sistema de identificación biométrica remota «en tiempo real» en un espacio de acceso público con fines de aplicación de la ley estará supeditado a la concesión de una autorización previa por parte de una autoridad judicial o una autoridad administrativa independiente del Estado miembro donde vaya a utilizarse dicho sistema, que la otorgarán previa solicitud motivada y de conformidad con las normas detalladas del Derecho interno mencionadas en el apartado 4. No obstante, en una situación de urgencia debidamente justificada, se podrá empezar a utilizar el sistema antes de obtener la autorización correspondiente, que podrá solicitarse durante el uso o después de este. La autoridad judicial o administrativa competente únicamente concederá la autorización cuando esté convencida, atendiendo a las pruebas objetivas o a los indicios claros que se le presenten, de que el uso del sistema de identificación biométrica remota «en tiempo real» es necesario y proporcionado para alcanzar alguno de los objetivos que figuran en el apartado 1, letra d), el cual se indicará en la solicitud. Al pronunciarse al respecto, la autoridad judicial o administrativa competente tendrá en cuenta los aspectos mencionados en el apartado 2. 4.Los Estados miembros podrán decidir contemplar la posibilidad de autorizar, ya sea total o parcialmente, el uso de sistemas de identificación biométrica remota «en tiempo real» en espacios de acceso público con fines de aplicación de la ley dentro de los límites y en las condiciones que se indican en el apartado 1, letra d), y los apartados 2 y 3. A tal fin, tendrán que establecer en sus respectivos Derechos internos las normas detalladas necesarias aplicables a la solicitud, la concesión y el ejercicio de las autorizaciones a que se refiere el apartado 3, así como a la supervisión de estas. Dichas normas especificarán también para cuáles de los objetivos enumerados en el apartado 1, letra d), y en su caso en relación con cuáles de los delitos indicados en su inciso iii), se podrá autorizar que las autoridades competentes utilicen esos sistemas con fines de aplicación de la ley. TÍTULO III SISTEMAS DE IA DE ALTO RIESGO Capítulo 1 CLASIFICACIÓN DE LOS SISTEMAS DE IA COMO SISTEMAS DE ALTO RIESGO
Metadata: {'articulo': 'Articulo 5'}
Score: 0.7545143128389454
